{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from  scipy.stats import norm\n",
    "from  scipy.stats import binom\n",
    "from scipy.stats import beta\n",
    "from  scipy.stats import uniform\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import pystan\n",
    "from pystan.constants import MAX_UINT\n",
    "\n",
    "%run ./tools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise A\n",
    "\n",
    "The goal of this exercise is to implement the Metropolis-Hastings method as seen in Lesson 5. Consider a variable y_i representing the number of success of an experiment i repeated n times. Now consider a vector Y containing the number of success of N independent experiments y_i. We assume that each experiment_i share a common probability of success $\\theta = 0.3$. Therefore we can generate the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "n = 100\n",
    "theta = 0.3\n",
    "\n",
    "Y = binom.rvs(n, theta, size=N)\n",
    "    \n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) We will assume a prior Beta distribution with parameters a=0.5 and b=0.5 for $\\theta$. Write the data likelihood p(Y|$\\theta$) and the posterior distribution p($\\theta$ | Y).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Estimate the posterior distirbution p($\\theta$|Y) using the Metropolis-Hastings algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposal(prop_mu, prop_sigma):\n",
    "    return scipy.stats.norm.rvs(loc = prop_mu, scale = prop_sigma, size = 1)\n",
    "\n",
    "def log_likelihood(param):\n",
    "    return np.sum([binom.logpmf(y_i,n,param) for y_i in Y])\n",
    "\n",
    "def log_prior(param):\n",
    "    return beta.logpdf(param, 0.5, 0.5)\n",
    "\n",
    "def log_posterior(param):\n",
    "    return log_likelihood(param) + log_prior(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Plot the posterior probability density functions obtained with the MCMC approximation and the analytical solution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise B\n",
    "\n",
    "This year a farmer ran an experiment  where he gave 10 cows medicine A and 10 medicine B and then measured whether they got sick (0) or not (1) during the summer season. Here is the resulting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cowA = np.array([0, 1, 0, 0, 0, 0, 1, 0, 0, 0])\n",
    "cowB = np.array([0, 0, 1, 1, 1, 0, 1, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) The farmer wants to know: How effective are the drugs? What is the evidence that medicine A is better or worse than medicine B ?**\n",
    "\n",
    "The outcome for each cow taking medecine A can be modeled as a random variable following a Bernouilli distribution with parameter $\\theta_1$. Similarly, the outcome for each cow taking medecine B can be modeled as a random variable following a Bernouilli distribution with parameter $\\theta_2$. Let's assume a unifrom prior for both $\\theta_1$ and $\\theta_2$. Our goal here is to obtain a posterior distribution of these two parameters. In this exercise, we propose to do it through the HMC method using the Pystan package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Earlier this year the farmer  ran an experiment where he gave 10 cows a special diet that could increase the milk production. He recorded the number of liters of milk from these “diet” cows and from 15 “normal” cows during one month. This is the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_milk = np.array([651., 679., 374., 601., 401., 609., 767., 709., 704., 679.])\n",
    "normal_milk = np.array([798., 1139., 529., 609., 553., 743., 151., 544., 488., 555., 257., 692., 678., 675., 538.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2a)** The farmer now wants to know: Was the diet any good, does it results in better milk production? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common approach here would be to model the milk production of each cow as a normal distribution. For the cows following a diet, their milk production can be modeled as $y_i \\sim \\mathcal{N}(\\mu_{diet}, \\sigma^{2}_{diet})$, while for normal cows the milk production can be modeled as $y_i \\sim \\mathcal{N}(\\mu_{normal}, \\sigma^{2}_{normal})$.\n",
    "We should also add priors for these four parameters. A lazy option here could be to assign them uniform priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** The farmer also has chickens. He tries different diets on them too with the hope that they will produce more eggs. Below is the number of eggs produced in one week by chickens on a diet and chickens eating normal chicken food:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet_eggs = np.array([6, 4, 2, 3, 4, 3, 0, 4, 0, 6, 3])\n",
    "normal_eggs =  np.array([4, 2, 1, 1, 2, 1, 2, 1, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3a)** The farmer now wants to know: Was the diet any good, does it result in the chickens producing more eggs ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we want to model count data, therefore a reasonable choice to model the number of eggs produced by the chickens would be a Poisson distribution. This distribution has one parameter $\\lambda$ which stands for the mean count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** The farmer is now wondering whether the amount of time a cow spends outside in the sunshine affects how much milk she produces. To test this he makes a controlled experiment where he picks out 20 cows and assigns to each of them a number of hours she should spend outside each day. The experiment runs for a month and the farmer records the number of liters of milk each cow produces. The data is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milk = np.array([685, 691, 476, 1151, 879, 725, 1190, 1107, 809, 539, 298, 805, 820, 498, 1026, 1217, 1177, 684, 1061, 834])\n",
    "\n",
    "hours = np.array([3, 7, 6, 10, 6, 5, 10, 11, 9, 3, 6, 6, 3, 5, 8, 11, 12, 9, 5, 5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4a)**  Using this data on hours of sunshine and resulting liters of milk the farmer wants to know: Does sunshine affect milk production positively or negatively?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
