<!doctype html>
<html lang="en">
  <head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="css/bootstrap.css" crossorigin="anonymous">

      <title>Marco Lorenzi</title>
  </head>

  <nav class="navbar navbar-expand-lg navbar-light bg-light">
    <a class="navbar-brand" href="./index.html">Marco Lorenzi</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarColor03" aria-controls="navbarColor03" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarColor03">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="nav-link" href="./research.html">Research</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="./cv.html">CV</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="./publications.html">Publications</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="./teaching.html">Teaching</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="./positions.html">Open positions</a>
        </li>
      </ul>
    </div>
  </nav>


  <!-- Optional JavaScript -->
  <!-- jQuery first, then Popper.js, then Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

  <div class="jumbotron">
 
      
  <h2> <a href = "http://univ-cotedazur.fr/en/idex/formations-idex/data-science/">  </a>
    </h2>      
      
  <ul class="nav nav-tabs">
  <li class="nav-item">
    <a class="nav-link active" data-toggle="tab" href="#bayesian_learning"><b>UCA MSc in Data Science</b><br/> Bayesian Learning</a>
  </li>
  <li class="nav-item">
    <a class="nav-link" data-toggle="tab" href="#model_selection"><b>UCA MSc in Data Science</b><br/> Model selection and resampling methods </a>
  </li>
  <li class="nav-item">
    <a class="nav-link" data-toggle="tab" href="#latent_variable">Latent variable models<br/> </a>
  </li>
  </ul>

<div id="myTabContent" class="tab-content">
    
  <div class="tab-pane fade active show" id="bayesian_learning">
    <hr class="my-4">
      
    <h4> Audience </h4>
        <ul>
            <li>Minimal background in mathematics and statistic</li>
             <ul style="list-style-type:none">
                <li>analysis and calculus (integral, derivatives, study of functions, … )</li>
                <li>basic statisticx concepts </li>
            </ul>
            <li>Minimal knowledge on statistical modeling</li>

            <li>Basic expertise with Python and Jupyter Notebook</li>
            <ul style="list-style-type:none">
                <li>installing new packages</li>
                <li>writing basic code and running pipelines</li>
                <li>knowledge of standard libraries (numpy, pandas, scikit-learn)</li>
            </ul>
        </ul>  
      
<!--
       <h4> Evaluation </h4>
      <p> Assignments: 3 in total, 10 points. <br> The completed assignments should be sent within 2 weeks from the release date. The notebook must be renamed as &ltcandidate name&gt_&ltcandidate surname&gt_&ltassignment_number&gt.ipynb  and sent to my email address. </p>
      <p> Final exam: 10 points </p>
-->
      
    <h4> Course Material </h4>  
      
    All the material is available on <a href="https://gitlab.inria.fr/epione_ML/bayesian-learning-uca"> GitLab </a>.  
      
    <table class="table table-hover">
        <thead>
        <tr class="table-primary">
        <th scope="col"> </th>
        <th scope="col"> Support slides </th>
        <th scope="col"> Notebook </th>
        <th scope="col"> Assignments</th>
        <th scope="col"> References</th>
        </tr>
        </thead>
        <tbody>
        <tr >
        <th scope="row">Day 1</th>
        <td> <a href="./material/Bayes/intro.pdf"> Introduction</a> </td>
        <td> <a href="./material/Bayes/Lesson1-no_solution.ipynb"> Basic Probability Theory </a>  </td>
        <td> / </td>
        <td> / </td>
        </tr>
<!--
        <tr >
        <th scope="row">Day 2</th>
        <td> / </td>
        <td> <a href="./material/Bayes/Lesson2_no-solutions.ipynb"> Probability Distributions </a>  </td>
        <td> / </td>
        <td> [BDA]:Ch1 </td>
        </tr> 
-->
        <tr >
        <th scope="row">Day 2</th>
        <td> / </td>
        <td> <a href="./material/Bayes/Lesson3_no_solution.ipynb"> Inference in Bayesian models: theory and practice </a>  </td>
 <!--       <td> <a href="./material/Bayes/assignment1.ipynb"> Assignments 1 </a>  </td>
-->
        <td> / </td>    
        <td> [BDA]:Ch1, [McE]:Ch3 </td>
        </tr>  
<!--
        <tr >    
        <th scope="row">Day 4 </th>
        <td> / </td>
        <td> <a href="./material/Bayes/ExerciseSession1_solved.ipynb"> Practical Exercises 1 </a>, ,  <a href="./material/Bayes/football_dataset.txt"> Data </a>   </td>
        <td> / </td>
        <td> [BDA]:Ch1, [McE]:Ch3 </td>
        </tr> 
-->
        <tr >
        <th scope="row">Day 3</th>
        <td>  / </td>
        <td> <a href="./material/Bayes/Lesson4-no_solution.ipynb"> Laplace approximation </a>, <a href="./material/Bayes/tools.py"> tools.py </a>,  <a href="https://github.com/rmcelreath/rethinking/blob/master/data/Howell1.csv"> Data (from [McE]) </a> </td>
        <td>  / </td>
        <td> [McE]:Ch4 </td>
        </tr>
        <tr >
        <th scope="row">Day 4</th>
        <td>  / </td>
        <td> <a href="./material/Bayes/Lesson5-no_solution.ipynb"> Bayesian linear regression </a> 
        </td>
        <td>  / </td>
        <td> [McE]:Ch4 </td>
        </tr>
<!--
        <tr >
        <th scope="row">Day 7</th>
        <td>  / </td>
        <td> <a href="./material/Bayes/ExerciseSession2_no_solutions.ipynb"> Practical exercises 2  </a> </td>
        <td> <a href="./material/Bayes/assignments2_2022.ipynb"> Assignments 2  </a>, <a href="./material/Bayes/data_assignments2.csv"> data  </a> </td>
        <td> [McE]:Ch8, Ch10 </td>
        </tr>
        <tr >
        <th scope="row">Day 8</th>
        <td>  / </td>
        <td> <a href="./material/Bayes/Lesson6_pystan3.0.ipynb"> MCMC  </a></td>
        <td> /  </td>
        <td> [McE]:Ch8, [Bet2018], [Stan] </td>
        </tr>
-->
<!--             
        <tr >
        <th scope="row">Day 9</th>
        <td>  / </td>
        <td> <a href="./material/Bayes/Lesson7-pystan3.ipynb"> Model Comparison and Logistic Regression  </a> </td>
        <td> <a href="./material/Bayes/assignment3-2022.ipynb"> Assignments 3  </a>, <a href="./material/Bayes/adni_data"> data  </a> </td>
        <td> [McE]:Ch8, Ch10, [Stan] </td>
        </tr>           
        <tr >
        <th scope="row">Day 9</th>
        <td>  / </td>
        <td><a href="./material/Bayes/Lesson7-pystan3.ipynb"> WAIC and Bayesian classification  </a>, <a href="./material/Bayes/Lesson7-pystan3.ipynb"> Pystan3.0 version  </a>   </td>
        <td>   </td>
        <td> / </td>
        </tr> 
        <tr >
        <th scope="row">Day 10</th>
        <td>  / </td>
        <td> <a href="./material/Bayes/ExerciseSession3_no_solution.ipynb"> Practical exercises 3  </a>, <a href="./material/Bayes/ExerciseSession3_pystan3_no_solution.ipynb"> Pystan3.0 version  </a>  </td>
        <td> / </td>
        <td> / </td>
        </tr>
-->
        </tbody>
    </table>
      
    <h4> References </h4>
      
    <p> [BDA] <i> Bayesian Data Analysis</i>.  A. Gelman, J.B. Carlin, H.S. Stern, D.B. Dunson, A. Vehtari, D.B. Rubin; Chapman and Hall/CRC, 2014, 3rd Edition. </p>
    <p> [McE] <i> Statistical Rethinking</i>.  R. McElreath; Chapman and Hall/CRC, 2016, 3rd Edition. </p>
      <p> [Bet2018] <i> A Conceptual Introduction to Hamiltonian Monte Carlo</i>.  M. Betancourt; <a href="https://arxiv.org/abs/1701.02434"> ArXiv </a> </p>
      <p> [Stan] <a href="https://mc-stan.org/users/documentation/"> <i> Stan Documentation</i> </a>.  Stan Development Team. </p>
      <p> [Pyro] <a href="https://pyro.ai/"> <i> Pyro website</i></a> </p>
  </div>
    
  <div class="tab-pane fade" id="model_selection">
  <hr class="my-4">
     <h4> Audience </h4>
        <ul>
            <li>Minimal background in mathematics and statistic</li>
             <ul style="list-style-type:none">
                <li>analysis and calculus (integral, derivatives, study of functions, … )</li>
                <li>basic statistical concepts (expectation, median, covariance, distributions, … )</li>
            </ul>
            <li>Minimal knowledge on statistical modeling</li>
            <ul style="list-style-type:none">
                <li>regression</li>
                <li>expectation, variance/covariance, statistical descriptors </li>
            </ul>
            <li>Basic expertise with Python and Jupyter Notebook</li>
            <ul style="list-style-type:none">
                <li>installing new packages</li>
                <li>writing basic code and running pipelines</li>
                <li>knowledge of standard libraries (numpy, pandas, scikit-learn)</li>
            </ul>
        </ul>  
      
       <h4> Evaluation </h4>
      <p> Three sessions of assignments: 10 points. <br> The completed assignments should be sent within 2 weeks from the release date. The notebook must be renamed as &ltcandidate name&gt_&ltcandidate surname&gt_&ltassignment_number&gt.ipynb  and sent to my email address. </p>
      <p> Final exam: 10 points </p>
      
    <h4> Course Material </h4>

      
    <table class="table table-hover">
        <thead>
        <tr class="table-primary">
        <th scope="col"> </th>
        <th scope="col"> Support slides </th>
        <th scope="col"> Notebook </th>
        <th scope="col"> Assignments</th>
        <th scope="col"> References</th>
        </tr>
        </thead>
        <tbody>
        <tr >
        <th scope="row">Day 1</th>
        <td> <a href="./material/intro.pdf"> Introduction</a> </td>
        <td> <a href="./material/Resampling/Lesson1.ipynb"> Basic Probability Models and Sampling in Python</a>  </td>
        <td> / </td>
        <td> / </td>
        </tr>             
        <tr>
        <th scope="row">Day 2</th>
        <td>  / </td>
        <td> <a href="./material/Resampling/lesson2.ipynb"> Data Generation - Regression & Classification </a>  </td>
        <td> / </td>
        <td> [Gu2003], [Gu2007] </td>
        </tr>
        <tr >
        <th scope="row">Day 3</th>
        <td>  / </td>
        <td> <a href="./material/Resampling/lesson3.ipynb"> Bias and Variance </a>  </td>
<!--        <td>  <a href="./material/Resampling/Assignments1.ipynb"> assignments 1 </a> </td>  -->
        <td>  / </td> 
        <td> [HTF2001]:Ch7, [Bis2006]:Ch1,Ch3, [Gem1992] </td>
        </tr>    
        <tr >
        <th scope="row">Day 4</th>
        <td>  / </td>
        <td> <a href="./material/Resampling/lesson4.ipynb"> Bootstrap and bagging </a>  </td>
        <td> / </td>
        <td> [Brei1996], [Efr1986], [HTF2001]:Ch7 </td>
        </tr>
        <tr >
        <th scope="row">Day 5</th>
        <td>  / </td>
        <td> <a href="./material/Resampling/lesson5.ipynb"> Cross-validation I </a>  </td>
         <td> / </td>    
<!--          <td>  <a href="./material/Resampling/Assignments%202.ipynb"> assignments 2 </a> </td>-->
        <td> [HTF2001]:Ch7 </td>
        </tr>
        <tr >
        <th scope="row">Day 6</th>
        <td>  / </td>
        <td> <a href="./material/Resampling/lesson6.ipynb"> Cross-validation II </a>  </td>
        <td> / </td>
        <td> [HTF2001]:Ch7,  [Koh1995], [Rao2008] </td>
        </tr>        
        <tr >
        <th scope="row">Day 7</th>
        <td>  / </td>
        <td> <a href="./material/Resampling/lesson7.ipynb"> Information Criteria I </a>  </td>
<!--          <td>   <a href="./material/Resampling/Assignments3.ipynb"> Assignment 3 </a> </td> -->
        <td>  / </td> 
        <td> [McE2016]:Ch6 </td>
        </tr>                   
        <tr >
        <th scope="row">Day 8</th>
        <td>  / </td>
        <td> <a href="./material/Resampling/lesson8.ipynb"> Information Criteria II </a>  </td>
        <td>      </td>
        <td> [McE2016]:Ch6, [Wag2004], [Sym2011]  </td>
        </tr> 
        <tr >
        <th scope="row">Day 9</th>
        <td>  / </td>
        <td> <a href="./material/Resampling/Class_exercises.ipynb"> Class exercises </a>  </td>
        <td>  /   </td>
        <td> / </td>
        </tr> 
        </tbody>        
    </table>

      
      
    <h4> References </h4>
      
      <p> [Gu2003] <i> Design of experiments for the NIPS 2003 variable selection benchmark</i>.  I. Guyon, 2003. <a href="http://clopinet.com/isabelle/Projects/NIPS2003/Slides/NIPS2003-Datasets.pdf"> link </a> </p>
      <p> [Gu2007] <i> Competitive baseline methods set new standards for the NIPS 2003 feature selection benchmark</i>. I. Guyon, J. Li, T. Mader, P.A. Pletscher, G. Schneider, M. Uhr. Pattern Recognition Letters, 28, 1438-1444, 2007. </p>
      <p> [HTF2001] <i> The Elements of Statistical Learning</i>. T. Hastie, R. Tibshirani, and J. Friedman. Springer Series in Statistics Springer New York Inc., New York, NY, USA, 2001.</p>
      <p> [Bis2006] <i> Pattern Recognition and Machine Learning</i>. 	C.M. Bishop. Springer-Verlag Berlin, Heidelberg, DE, 2006.	
      </p>
      <p> [Gem1992] <i> Neural networks and the bias/variance dilemma</i>. 	S. Geman, E. Bienenstock, R Doursat. Neural Computation, 4:2, 1-58, 1992. </p>	
      <p> [Brei1996] <i> Bagging predictors </i>. L. Breiman. Machine learning, 24(2), 123-140, 1996 </p>
      <p> [Efr1986] <i>  Bootstrap methods for standard errors, confidence intervals, and other measures of statistical accuracy</i>. B. Efron,  R. Tibshirani, Statistical science, 54-75. 1986. </p>
      <p> [Koh1995] <i> A study of cross-validation and bootstrap for accuracy estimation and model selection</i>. R. Kohavi. IJCAI, 14:2, 1995.</p>
      <p> [Rao2008] <i> On the dangers of cross-validation. An experimental evaluation. </i> R. Barat Rao, G. Fung, and R. Rosales. Proceedings of the 2008 SIAM International Conference on Data Mining. Society for Industrial and Applied Mathematics, 2008.  </p>
      <p> [McE2016] <i> Statistical Rethinking. A Bayesian Course with Examples in R and Stan. </i> R. McElreath. T&F Crc Press, 2016.  </p>
      <p> [Wag2004] <i> AIC model selection using Akaike weights.</i> E.J. Wagenmakers , S. Farrell. Psychon Bull Rev. 11(1):192-6, 2004.  </p>
      <p> [Sym2011]  <i> A brief guide to model selection, multimodel inference and model averaging in behavioural ecology using Akaike’s information criterion.</i> M.R. Symonds, A. Moussalli, A. Behavioral Ecology and Sociobiology, 65(1), 13-21, 2011. </p>
      
  </div>
    
  <div class="tab-pane fade" id="latent_variable">
    <hr class="my-4">
      
    <h4> Support material for Winter School in Imaging Genetics 2019, Verona University, Italy</h4>
              
    This lecture aims at covering the statistical background required to perform association analysis in typical imaging-genetics studies. We will introduce the notion of statistical association, and highlight the standard analysis paradigm in univariate modeling. We will then explore multivariate association models, generalizing to high-dimensional data the notion of statistical association. In particular, we will focus on standard paradigms such as Canonical Correlation Analysis (CCA), Partial Least Squares (PLS), and Reduced Rank Regression (RRR). We will finally introduce more advanced analysis frameworks, such as Bayesian and deep association methods. Within this context we will present the Multi-Channel Variational Autoencoder, recently developed by our group.
    
    <br/> 
    <br/> 
     
    <button type="button" class="btn btn-outline-info"><a href="./material/winter_school/Imaging_Genetics_Book_Chapter.pdf"> (The hitchhiker‘s guide to) Imaging-Genetics </a></button>      
        
    <button type="button" class="btn btn-outline-info"><a href="./material/winter_school/Lorenzi_latent_variable_models.ipynb"> Colab notebook </a></button>    
    
    <button type="button" class="btn btn-outline-info"><a href="./material/winter_school/Imaging-Genetics-winter_school_Verona_2019_compressed.pdf"> Presentation </a></button> 
        
    <br/>
    <br/> 
<!--
    <div class="alert alert-dismissible alert-info">
  <button type="button" class="close" data-dismiss="alert">&times;</button>
   
   </div>    
-->
   

    
    <h2> References </h2>
      
    <p> P. Geladi and B. Kowalski.<i> Partial least-squares regression: a tutorial</i>, Analytica Chimica Acta, 1985. </p>
    <p> S. Szymczak, J.M. Biernacka, H.J. Cordell, O. González-Recio, I.R. König, H. Zhang, Y.V. Sun. <i>Machine learning in genome‐wide association studies</i>, Genetic Epidemiology 2009. </p>
    <p> M. Silver, E. Janousova, X. Hua, P.M. Thompson, G. Montana. <i>Identification of gene pathways implicated in Alzheimer's disease using longitudinal imaging phenotypes with sparse regression</i>, NeuroImage 2012. </p>
    <p> E. Le Floch, V. Guillemot, V. Frouin, P. Pinel, C. Lalanne, L. Trinchera, A. Tenenhaus, A. Moreno, M. Zilbovicius, T. Bourgeron, S. Dehaene, B. Thirion, J.B. Poline, E. Duchesnay. <i>Significant correlation between a set of genetic polymorphisms and a functional brain network revealed by feature selection and sparse Partial Least Squares</i>. Neuroimage. 2012 Oct 15;63(1):11-24.</p>
    <p> J. Liu and V. Calhoun. <i>A review of multivariate analyses in imaging genetics</i>, Frontiers in Neuroinformatics, 2014. </p>
    <p> M. Lorenzi, A. Altmann, B. Gutman, S. Wray, C. Arber, D.P. Hibar, N. Jahanshad, J.M. Schott, D.C. Alexander, P.M. Thompson, S. Ourselin. <i>Susceptibility of brain atrophy to TRIB3 in Alzheimer’s disease, evidence from functional prioritization in imaging genetics</i>. PNAS March 20, 2018 115 (12) 3162-3167.</p>
    <p> L. Antelmi, N. Ayache, P. Robert, M. Lorenzi. <i>Sparse Multi-Channel Variational Autoencoder for the Joint Analysis of Heterogeneous Data</i>. 36th International Conference on Machine Learning (ICML), 2019. </p>
    <p> L. Shen and P.M. Thompson. <i>Brain Imaging Genomics: Integrated Analysis and Machine Learning</i>. Proceedings of the IEEE, 2019. </p>
  </div>
    
</div>
      
      
      
<!--    <hr class="my-4">-->
      
    

  </div>

</html>


